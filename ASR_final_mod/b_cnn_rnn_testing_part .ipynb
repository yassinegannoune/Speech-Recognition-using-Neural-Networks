{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPeYWcfc9UKB",
        "outputId": "c510d7a2-2bec-4e7b-f52e-d31c14c8880c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5886 sha256=215f431061833e242dc4741f92039bad81486d87bba0e971dd31dfb014a6b372\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n"
          ]
        }
      ],
      "source": [
        "pip install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "# Set the path to the librispeech folder\n",
        "librispeech_path = \"/content/drive/MyDrive/LibriSpeech\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwUpu4c99jLs",
        "outputId": "52d81c8e-0279-41b5-805f-b079a77f3ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n"
      ],
      "metadata": {
        "id": "pmL9JO0O9cHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU preparation\n",
        "from keras.backend import set_session\n",
        "import tensorflow as tf \n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from sample_models import *\n",
        "from train_utils import train_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR8kqJzu9eh2",
        "outputId": "7ef1604c-3118-4669-dcea-e27d33028bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = cnn_rnn_model(input_dim=161, \n",
        "                        filters=200,\n",
        "                        kernel_size=11, \n",
        "                        conv_stride=2,\n",
        "                        conv_border_mode='valid',\n",
        "                        units=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43IsM0HC9nLm",
        "outputId": "8237f7df-17fa-4b84-db12-08c88feff088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None, 161)]       0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 200)         354400    \n",
            "                                                                 \n",
            " bn_conv_1d (BatchNormalizat  (None, None, 200)        800       \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " rnn (CuDNNGRU)              (None, None, 200)         241200    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, None, 200)        800       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 29)         5829      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " softmax (Activation)        (None, None, 29)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,029\n",
            "Trainable params: 602,229\n",
            "Non-trainable params: 800\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(input_to_softmax=model_2, \n",
        "            pickle_path='model_2.pickle', \n",
        "            save_model_path='model_2.h5', \n",
        "            spectrogram=True) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlhaX76h9sIm",
        "outputId": "88d7592b-71cc-4a67-f1bb-39402b02c3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/train_utils.py:74: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist = model.fit_generator(generator=audio_gen.next_train(), steps_per_epoch=steps_per_epoch,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "106/106 [==============================] - 3285s 31s/step - loss: 263.4915 - val_loss: 224.4163\n",
            "Epoch 2/30\n",
            "106/106 [==============================] - 101s 956ms/step - loss: 178.3881 - val_loss: 171.2186\n",
            "Epoch 3/30\n",
            "106/106 [==============================] - 84s 792ms/step - loss: 158.8696 - val_loss: 154.4125\n",
            "Epoch 4/30\n",
            "106/106 [==============================] - 82s 776ms/step - loss: 149.5786 - val_loss: 143.8856\n",
            "Epoch 5/30\n",
            "106/106 [==============================] - 80s 754ms/step - loss: 142.8584 - val_loss: 144.1737\n",
            "Epoch 6/30\n",
            "106/106 [==============================] - 79s 746ms/step - loss: 140.0500 - val_loss: 139.4100\n",
            "Epoch 7/30\n",
            "106/106 [==============================] - 84s 798ms/step - loss: 134.8718 - val_loss: 141.4298\n",
            "Epoch 8/30\n",
            "106/106 [==============================] - 85s 800ms/step - loss: 132.8446 - val_loss: 142.8406\n",
            "Epoch 9/30\n",
            "106/106 [==============================] - 79s 752ms/step - loss: 130.2332 - val_loss: 139.4320\n",
            "Epoch 10/30\n",
            "106/106 [==============================] - 79s 745ms/step - loss: 131.0509 - val_loss: 138.7838\n",
            "Epoch 11/30\n",
            "106/106 [==============================] - 79s 751ms/step - loss: 129.7222 - val_loss: 138.2093\n",
            "Epoch 12/30\n",
            "106/106 [==============================] - 79s 744ms/step - loss: 127.6118 - val_loss: 134.8752\n",
            "Epoch 13/30\n",
            "106/106 [==============================] - 78s 740ms/step - loss: 128.8309 - val_loss: 140.4283\n",
            "Epoch 14/30\n",
            "106/106 [==============================] - 79s 747ms/step - loss: 129.6386 - val_loss: 136.2664\n",
            "Epoch 15/30\n",
            "106/106 [==============================] - 79s 745ms/step - loss: 128.1303 - val_loss: 140.4212\n",
            "Epoch 16/30\n",
            "106/106 [==============================] - 77s 733ms/step - loss: 127.0788 - val_loss: 135.9304\n",
            "Epoch 17/30\n",
            "106/106 [==============================] - 79s 749ms/step - loss: 128.3007 - val_loss: 144.6963\n",
            "Epoch 18/30\n",
            "106/106 [==============================] - 78s 743ms/step - loss: 132.4801 - val_loss: 145.1095\n",
            "Epoch 19/30\n",
            "106/106 [==============================] - 79s 746ms/step - loss: 131.5701 - val_loss: 140.3083\n",
            "Epoch 20/30\n",
            "106/106 [==============================] - 79s 747ms/step - loss: 131.6816 - val_loss: 142.9529\n",
            "Epoch 21/30\n",
            "106/106 [==============================] - 80s 753ms/step - loss: 131.1236 - val_loss: 135.3365\n",
            "Epoch 22/30\n",
            "106/106 [==============================] - 78s 741ms/step - loss: 131.5521 - val_loss: 137.6540\n",
            "Epoch 23/30\n",
            "106/106 [==============================] - 79s 746ms/step - loss: 131.6243 - val_loss: 146.4334\n",
            "Epoch 24/30\n",
            "106/106 [==============================] - 78s 741ms/step - loss: 132.0097 - val_loss: 138.4677\n",
            "Epoch 25/30\n",
            "106/106 [==============================] - 78s 743ms/step - loss: 131.4947 - val_loss: 143.8418\n",
            "Epoch 26/30\n",
            "106/106 [==============================] - 78s 743ms/step - loss: 132.9633 - val_loss: 142.0711\n",
            "Epoch 27/30\n",
            "106/106 [==============================] - 79s 746ms/step - loss: 133.8557 - val_loss: 145.4436\n",
            "Epoch 28/30\n",
            "106/106 [==============================] - 78s 740ms/step - loss: 132.3800 - val_loss: 139.4351\n",
            "Epoch 29/30\n",
            "106/106 [==============================] - 78s 737ms/step - loss: 134.5549 - val_loss: 145.2643\n",
            "Epoch 30/30\n",
            "106/106 [==============================] - 78s 739ms/step - loss: 133.6337 - val_loss: 144.2990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from data_generator import AudioGenerator\n",
        "from keras import backend as K\n",
        "from utils import int_sequence_to_text\n",
        "from IPython.display import Audio\n",
        "\n",
        "def get_predictions(index, partition, input_to_softmax, model_path):\n",
        "    # load the train and test data\n",
        "    data_gen = AudioGenerator()\n",
        "    data_gen.load_train_data()\n",
        "    data_gen.load_validation_data()\n",
        "    \n",
        "    # obtain  transcription and the audio features \n",
        "    if partition == 'validation':\n",
        "        transcr = data_gen.valid_texts[index]\n",
        "        audio_path = data_gen.valid_audio_paths[index]\n",
        "        data_point = data_gen.normalize(data_gen.featurize(audio_path))\n",
        "    elif partition == 'train':\n",
        "        transcr = data_gen.train_texts[index]\n",
        "        audio_path = data_gen.train_audio_paths[index]\n",
        "        print(audio_path)\n",
        "        data_point = data_gen.normalize(data_gen.featurize(audio_path))\n",
        "    else:\n",
        "        raise Exception('Invalid partition!  Must be \"train\" or \"validation\"')\n",
        "        \n",
        "    # obtain and decode the  model's predictions\n",
        "    input_to_softmax.load_weights(model_path)\n",
        "    prediction = input_to_softmax.predict(np.expand_dims(data_point, axis=0))\n",
        "    output_length = [input_to_softmax.output_length(data_point.shape[0])] \n",
        "    pred_ints = (K.eval(K.ctc_decode(\n",
        "                prediction, output_length)[0][0])+1).flatten().tolist()\n",
        "    print(pred_ints)\n",
        "    \n",
        "    # play the audio file, and display the true and predicted transcriptions\n",
        "    print('-'*80)\n",
        "    Audio(audio_path)\n",
        "    print('True transcription:\\n' + '\\n' + transcr)\n",
        "    print('-'*80)\n",
        "    print('Predicted transcription:\\n' + '\\n' + ''.join(int_sequence_to_text(pred_ints)))\n",
        "    print('-'*80)"
      ],
      "metadata": {
        "id": "0nkQyOoHWiYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_predictions(index=200, \n",
        "                partition='train',\n",
        "                input_to_softmax=model_2, \n",
        "                model_path='results/model_2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKwH6gVcWycb",
        "outputId": "4f16e7fb-d872-4781-f167-ac5d409ef20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LibriSpeech/dev-clean/6241/66616/6241-66616-0013.wav\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "[17, 21, 2, 18, 7, 4, 17, 2, 22, 10, 7, 2, 21, 17, 15, 16, 2, 14, 17, 2, 14, 17, 17, 2, 18, 10, 7, 2, 25, 17, 11, 21, 2, 4, 7, 3, 21, 18, 3, 5, 11, 17, 14, 7, 2, 6, 3, 7, 2, 17, 16, 3, 2, 6, 7, 18, 20, 7, 6, 3, 5, 11, 17, 16, 2, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "--------------------------------------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "it was at about this time in their lives that the woongas became especially daring in their depredations\n",
            "--------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "os pebo the somn lo loo phe wois beaspaciole dae ona depredacion s\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the model\n",
        "model_end = final_model(input_dim=161, \n",
        "                        units=200,\n",
        "                        filters=200,\n",
        "                        kernel_size=11, \n",
        "                        conv_stride=2,\n",
        "                        conv_border_mode='valid',\n",
        "                        recur_layers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dsi5zktXqju",
        "outputId": "79a46376-a2e3-45da-d240-fce38503a8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None, 161)]       0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 200)         354400    \n",
            "                                                                 \n",
            " bn_conv_1d (BatchNormalizat  (None, None, 200)        800       \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, None, 200)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 200)         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 400)        482400    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, None, 400)        1600      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 400)         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, None, 400)        722400    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, None, 400)        1600      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 400)         0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, None, 29)         11629     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " softmax (Activation)        (None, None, 29)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,574,829\n",
            "Trainable params: 1,572,829\n",
            "Non-trainable params: 2,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_predictions(index=1, \n",
        "                partition='train',\n",
        "                input_to_softmax=model_end, \n",
        "                model_path='results/model_end.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ixLLqW-XzKR",
        "outputId": "4548c2d4-1b0a-4006-de31-7d2d77cd7ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LibriSpeech/dev-clean/6295/64301/6295-64301-0002.wav\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "[25, 3, 21, 2, 22, 10, 20, 2, 7, 24, 7, 20, 2, 10, 2, 10, 3, 18, 7, 20, 2, 15, 3, 16, 2, 22, 10, 3, 16, 2, 12, 17, 21, 17, 10, 2, 22, 10, 3, 22, 2, 16, 11, 2, 11, 21, 2, 7, 2, 21, 22, 20, 17, 6, 2, 3, 14, 17, 16, 2, 10, 2, 8, 17, 2, 18, 3, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "--------------------------------------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "was there ever a happier man than joseph that night as he strode along the footpath\n",
            "--------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "was thr ever h haper man than josoh that ni is e strod alon h fo pat\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_predictions(index=0, \n",
        "                partition='validation',\n",
        "                input_to_softmax=model_end, \n",
        "                model_path='results/model_end.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJ98lKuX1Of",
        "outputId": "04b9adb1-eb18-4e9b-9396-6cc48aef3aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n",
            "[22, 10, 7, 16, 27, 10, 7, 20, 2, 20, 3, 21, 10, 6, 17, 16, 21, 2, 21, 22, 7, 7, 20, 21, 2, 16, 2, 22, 17, 2, 14, 7, 5, 17, 20, 11, 22, 27, 2, 17, 20, 6, 2, 21, 10, 17, 25, 6, 11, 16, 9, 2, 14, 2, 22, 14, 27, 2, 8, 17, 20, 2, 7, 2, 21, 17, 14, 6, 7, 20, 21, 17, 16, 2, 22, 20, 11, 16, 11, 16, 9, 2, 22, 17, 2, 18, 3, 22, 5, 22, 2, 7, 24, 7, 20, 27, 2, 17, 16, 2, 11, 16, 9, 2, 3, 21, 2, 22, 11, 15, 2, 15, 11, 16, 2, 7, 21, 2, 17, 22, 2, 22, 10, 2, 21, 17, 14, 7, 2, 15, 7, 2, 25, 3, 21, 2, 16, 17, 20, 27, 2, 5, 3, 23, 22, 10, 11, 17, 16, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "--------------------------------------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "then he rushed down stairs into the courtyard shouting loudly for his soldiers and threatening to patch everybody in his dominions if the sailorman was not recaptured\n",
            "--------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "thenyher rashdons steers n to lecority ord showding l tly for e solderson trining to patct every on ing as tim min es ot th sole me was nory cauthiond\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}